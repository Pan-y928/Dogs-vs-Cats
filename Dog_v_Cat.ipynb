{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog v Cat",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZtvUWJ9vwiw8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dog vs Cat"
      ]
    },
    {
      "metadata": {
        "id": "E8AlTrCSwmYJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.0 Intro \n",
        "\n",
        "- **Problem**: training a deep CNN from scratch to distinguish dogs from cats.\n",
        "- **Data**: [Github link](https://github.com/RootofalleviI/Dog-vs-Cat/blob/master/Data/cats_and_dogs_small.zip)\n",
        "- **Source of data**:  [Kaggle competition - Dog vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
        "\n",
        "<span style=\"color:red\">**If you are running this on Colab, make sure you enable GPU!!!**</span>"
      ]
    },
    {
      "metadata": {
        "id": "0Dptsxhty0kS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.0 Environment\n",
        "\n",
        "### 2.1 Unzip data\n",
        "\n",
        "- Please first download the data from the github link above as its directory structure has been set up already.\n",
        "- If you are running this notebook on Colab, you need to upload the zip file to Colab environment then proceed to the next step.\n",
        "- If you are running this notebook on your local server, simply put the zip file in the same directory as your notebook."
      ]
    },
    {
      "metadata": {
        "id": "-HgMJHnKH820",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "unzip_target_dir = '.' \n",
        "with zipfile.ZipFile('./cats_and_dogs_small.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall(unzip_target_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oTtHiAw7gyj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Comment out this entire block if you are running locally.\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GwYrkac1Hpa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Define constants for training, validation, and test data\n",
        "\n",
        "There are 4000 images in total, 2000 for cats and 2000 for dogs. We use 1000 from each category as training data, 500 for validation and 500 for test."
      ]
    },
    {
      "metadata": {
        "id": "X25WJIIORo6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = './cats_and_dogs_small'; \n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "\n",
        "print('Folder structure:', os.listdir('./cats_and_dogs_small'))\n",
        "print('Total traing cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('Total traing dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('Total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "print('Total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('Total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('Total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xkr-SX7y13Wk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.0 Naive CNN"
      ]
    },
    {
      "metadata": {
        "id": "-uOPoax42cwb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Model"
      ]
    },
    {
      "metadata": {
        "id": "kIuVfqpgQtba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras import layers, models, optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hld6G9rwQx4f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Data Preprocessing\n",
        "\n",
        "\n",
        "1. Read the source files (images).\n",
        "2. Decode the JPEG content to RGB grids of pixels.\n",
        "3. Convert these into floating-point tensors.\n",
        "4. Rescale the pixel values from a value in [0, 255] to a value in [0, 1].\n",
        "\n",
        "Documentation on ImageDataGenerator: https://keras.io/preprocessing/image/"
      ]
    },
    {
      "metadata": {
        "id": "OSJYgu-mRBwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,                \n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "for data_batch, labels_batch in train_generator:\n",
        "  print('data batch shape:', data_batch.shape)\n",
        "  print('labels batch shape:', labels_batch.shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EnqIlnDo4htH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3 Training\n",
        "\n",
        "Again, if you are on Colab, make sure you have enabled GPU -- it's a matter of minutes vs. hours."
      ]
    },
    {
      "metadata": {
        "id": "eB2Eu7pPSffv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100, # batch_size = 20 => 100 batch = 2000 samples\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")\n",
        "\n",
        "model.save('cats_and_dogs_small_naive_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MnKG9XLZBt-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you are on Colab and want to download the file, uncomment this\n",
        "# files.download('cats_and_dogs_small_naive_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3mnMxW6B5_r8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.4 Plotting"
      ]
    },
    {
      "metadata": {
        "id": "CX27FIG2URII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'm', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'm', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ns5XX0uj6MRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.0 Improvement"
      ]
    },
    {
      "metadata": {
        "id": "QrCJG2if6Quv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1 Data Augmentation\n",
        "\n",
        "We augment the samples via a number of random transformation that yield believable-looking images. This helps expose the model to more aspects of the data and in turn makes it generalize better.\n"
      ]
    },
    {
      "metadata": {
        "id": "L4r78U-5Ux-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,         # - rescale\n",
        "    rotation_range=40,      # - degrees\n",
        "    width_shift_range=0.2,  # - ranges as a fraction of total width or height \n",
        "    height_shift_range=0.2, #   to randomly translate\n",
        "    shear_range=0.2,        # - shearing\n",
        "    zoom_range=0.2,         # - zooming \n",
        "    horizontal_flip=True,   # - horizontal flip\n",
        "    fill_mode='nearest'     # - strategy to fill the newly created pixels\n",
        ")\n",
        "\n",
        "# We are not augmenting test data\n",
        "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,      # - degrees\n",
        "    width_shift_range=0.2,  # - ranges as a fraction of total width or height \n",
        "    height_shift_range=0.2, #   to randomly translate\n",
        "    shear_range=0.2,        # - shearing\n",
        "    zoom_range=0.2,         # - zooming \n",
        "    horizontal_flip=True,   # - horizontal flip\n",
        "    fill_mode='nearest'     # - strategy to fill the newly created pixels\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-yqjfJH7BJs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 Adding Dropouts\n",
        "\n",
        "To further fight overfitting, we add a Dropout layer right before the densely connected classifier."
      ]
    },
    {
      "metadata": {
        "id": "CpzUhvI7VVjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoCLD796VDbz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.3 Train"
      ]
    },
    {
      "metadata": {
        "id": "Dc0CuD-uV10z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import time\n",
        "\n",
        "# Use checkpoints here as it takes a bit longer\n",
        "filepath=\"./weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath, \n",
        "    monitor='val_acc', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    mode='max', \n",
        "    period=5 # Checkpoints after each 5 iterations\n",
        ")\n",
        "\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50,\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "\n",
        "model.save('cats_and_dogs_small_improved.h5')\n",
        "\n",
        "# Uncomment if you want to download the model\n",
        "# files.download('cats_and_dogs_small_improved.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnrMS51HVAPr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.4 Plotting"
      ]
    },
    {
      "metadata": {
        "id": "uoB2wjp5R_b8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'm', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'm', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdOhMI8SSQjD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5.0 Pretrained Model"
      ]
    },
    {
      "metadata": {
        "id": "sxqrWcNASfy-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.1 VGG16\n",
        "\n",
        "The VGG16 architecture is a simple and widely used convnet architecture for ImageNet. We will use its convolutional base and train our own dense classifier on top of it."
      ]
    },
    {
      "metadata": {
        "id": "fKqf9N4BSwVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(\n",
        "    weights='imagenet',  # weight checkpoint from which we initialize the model\n",
        "    include_top=False,    # discard the classifier, only conv base is needed\n",
        "    input_shape=(150, 150, 3)\n",
        ")\n",
        "\n",
        "# Build the new model by adding a dense layer on top of conv_base\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rla5i5tvTpEC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.2 Freeze Base and Train Classifier\n",
        "\n",
        "We freeze the conv base so that back-prop won't destroy its already-learned weight."
      ]
    },
    {
      "metadata": {
        "id": "oNVdWYrVT-yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6qGBrPNUCiB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.3 Train the model\n",
        "\n",
        "Note that the training data has already been augmented from above."
      ]
    },
    {
      "metadata": {
        "id": "HkRuFr3AUH75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SkYEwZHrUmej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")\n",
        "\n",
        "model.save('cats_and_dog_small_pretrained.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CbSofF3MUw5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.4 Plotting"
      ]
    },
    {
      "metadata": {
        "id": "4XLrQHG0VOnH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'm', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'm', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Vto2phAaPVt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.5 Fine-tuning\n",
        "\n",
        "Now we unfreeze the last three layers of conv base and train them along with the classifier."
      ]
    },
    {
      "metadata": {
        "id": "th2jQboPaawV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsBp_YZQaxPX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50\n",
        ")\n",
        "\n",
        "model.save('cats_and_dog_full_pretrained_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Efqn8xvRa_E2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.6 Plotting"
      ]
    },
    {
      "metadata": {
        "id": "p5Sw6Bue-GbK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('cats_and_dog_full_pretrained_final.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRw1d1RNbC7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'm', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'm', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iqZmFj1VbDvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.7 Make Predictions\n",
        "\n",
        "Finally, we use the test set to measure the accuracy of our final model -- around 97%."
      ]
    },
    {
      "metadata": {
        "id": "OVKMNl6zblme",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print(\"test acc:\", test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}